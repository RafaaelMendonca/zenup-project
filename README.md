# ğŸ§  ZenUp Project â€” Chatbot Emocional com FastAPI + Redis + Groq

![Python](https://img.shields.io/badge/Python-3.10%2B-blue)
![FastAPI](https://img.shields.io/badge/FastAPI-Framework-brightgreen)
![Redis](https://img.shields.io/badge/Redis-Cache-red)
![Groq API](https://img.shields.io/badge/Groq-LLM-orange)
![License](https://img.shields.io/badge/license-MIT-lightgrey)

---

## ğŸ“‘ Ãndice

1. VisÃ£o Geral  
2. Arquitetura do Projeto  
3. InstalaÃ§Ã£o e ConfiguraÃ§Ã£o  
4. Endpoints da API  
5. SeguranÃ§a e Boas PrÃ¡ticas  
6. Fluxo de Funcionamento  
7. ExecuÃ§Ã£o Local  
8. Tecnologias Utilizadas  
9. Autor  
10. LicenÃ§a  

---

## ğŸš€ VisÃ£o Geral

O **ZenUp Project** Ã© um chatbot de **apoio emocional seguro**, construÃ­do em **Python (FastAPI)** e integrado ao **Redis** para armazenar o histÃ³rico de conversas.  
Ele se conecta ao **Groq API** (modelo *Llama 3.3-70b-versatile*) para gerar respostas empÃ¡ticas e coerentes, com foco em **seguranÃ§a emocional**, **contexto persistente** e **tratamento responsÃ¡vel de crises**.

---

## ğŸ§© Arquitetura do Projeto

zenup-project/  
â”œâ”€â”€ chatbot/  
â”‚   â””â”€â”€ chatbot.py                # NÃºcleo lÃ³gico e integraÃ§Ã£o com Groq API  
â”œâ”€â”€ controllers/  
â”‚   â””â”€â”€ chatbot_controller.py     # Rotas e autenticaÃ§Ã£o  
â”œâ”€â”€ model/  
â”‚   â””â”€â”€ redis_model.py            # Gerenciamento do histÃ³rico via Redis  
â”œâ”€â”€ main.py                       # InicializaÃ§Ã£o da API FastAPI  
â”œâ”€â”€ requirements.txt              # DependÃªncias do projeto  
â”œâ”€â”€ .env                          # VariÃ¡veis de ambiente  
â””â”€â”€ venv/                         # Ambiente virtual local  

---

## âš™ï¸ï¸ InstalaÃ§Ã£o e ConfiguraÃ§Ã£o

### 1ï¸âƒ£ Clone o repositÃ³rio  
git clone https://github.com/RafaaelMendonca/zenup-project.git  
cd zenup-project  

### 2ï¸âƒ£ Crie e ative o ambiente virtual  
python -m venv venv  

**Linux / Mac**  
source venv/bin/activate  

**Windows**  
venv\Scripts\activate  

### 3ï¸âƒ£ Instale as dependÃªncias  
pip install -r requirements.txt  

### 4ï¸âƒ£ Configure o arquivo `.env`  
Crie o arquivo `.env` na raiz do projeto e adicione:  

API_SECRET_KEY=sua_chave_secreta  
GROQ_API_KEY=sua_chave_groq  
REDIS_HOST=localhost  
REDIS_PORT=6379  

---

## ğŸ’¬ Endpoints da API

### ğŸ” 1. Login  
Gera o token de acesso para autenticaÃ§Ã£o nos demais endpoints.  

**Endpoint:**  
POST /login  

**Body:**  
{  
  "chave": "sua_chave_de_api"  
}  

**Resposta:**  
{  
  "token": **token_gerado**
}  

---

### ğŸ§  2. Chat  
Recebe uma mensagem do usuÃ¡rio e retorna a resposta gerada pelo modelo LLM da Groq.  

**Endpoint:**  
POST /chat  

**Headers:**  
Authorization: Bearer **TOKEN**
Content-Type: application/json  

**Body:**  
{  
    "id": 123,  
    "texto": "estou me sentindo muito triste"  
}  

**Resposta:**  
{  
    "mensagem": "Sinto muito que vocÃª esteja passando por isso. Estou aqui para ouvir e apoiar vocÃª."  
}  

âœ… Forma correta de chamar o `/chat`:  

Corpo da requisiÃ§Ã£o:  
{  
  "id": 123,  
  "texto": "estou me sentindo muito triste"  
}  

CabeÃ§alho (headers):  
Authorization: Bearer **TOKEN**
Content-Type: application/json  

---

### ğŸ§¾ 3. Gerar Resumo  
Gera um resumo do histÃ³rico de conversa armazenado no Redis.  

**Endpoint:**  
GET /resumo/{id_usuario}  

**Headers:**  
Authorization: Bearer **TOKEN** 

**Resposta:**  
{  
    "resumo": "O usuÃ¡rio expressou sentimentos de tristeza e busca apoio emocional."  
}  

---

### ğŸ¤– 4. Mensagem Proativa  
Gera uma mensagem automÃ¡tica de apoio emocional ao usuÃ¡rio.  

**Endpoint:**  
GET /ia_proativa/{id_usuario}  

**Resposta:**  
{  
    "mensagem": "OlÃ¡! Notei que vocÃª estÃ¡ passando por momentos difÃ­ceis. Estou aqui para ouvir e fornecer apoio emocional."  
}  

---

## ğŸ›¡ï¸ SeguranÃ§a e Boas PrÃ¡ticas

| Mecanismo | DescriÃ§Ã£o |  
|------------|------------|  
| AutenticaÃ§Ã£o | Via token gerado no `/login` com base na `API_SECRET_KEY`. |  
| SanitizaÃ§Ã£o | Todo texto Ã© filtrado antes de ser enviado ao modelo. |  
| DetecÃ§Ã£o de Crise | Regex detecta frases de autoagressÃ£o ou risco. |  
| Limite de Mensagens | Cada mensagem Ã© truncada para 4000 caracteres. |  
| ProteÃ§Ã£o contra Prompt Injection | Remove tokens como `role: system` e `instruÃ§Ãµes:`. |  
| ConexÃ£o Segura com Redis | OperaÃ§Ãµes envoltas em try/except com logs de erro. |  

---

## ğŸ§± Fluxo de Funcionamento

Fluxo simplificado de execuÃ§Ã£o:

UsuÃ¡rio â†’ API `/login` â†’ Retorna token  
UsuÃ¡rio â†’ API `/chat` â†’ Armazena mensagem no Redis  
API â†’ Groq (modelo Llama 3.3) â†’ Gera resposta  
Resposta â†’ Redis â†’ UsuÃ¡rio  

---

## ğŸ§° Tecnologias Utilizadas

| Tecnologia | FunÃ§Ã£o |  
|-------------|--------|  
| Python 3.10+ | Linguagem principal |  
| FastAPI | Framework de API assÃ­ncrona |  
| Redis | Armazenamento de contexto e cache |  
| Groq API | LLM (Llama 3.3) para geraÃ§Ã£o de respostas |  
| dotenv | Gerenciamento de variÃ¡veis de ambiente |  
| Pydantic | ValidaÃ§Ã£o e tipagem dos dados |  
| Logging | Registro de erros e auditoria |  
| Secrets | GeraÃ§Ã£o de tokens seguros |  

---

## ğŸ§  ExecuÃ§Ã£o Local

Para executar o servidor localmente:  

uvicorn main:app --reload  

Acesse:  
http://127.0.0.1:8000/docs  

---

## ğŸ‘¨â€ğŸ’» Autor

**Rafael MendonÃ§a**  
ğŸ“§ contato.rafael2023@gmail.com
ğŸ’¼ [LinkedIn](https://www.linkedin.com/in/rafaaelmendonca/)  
ğŸ™ [GitHub](https://github.com/RafaaelMendonca)  

---

## ğŸ·ï¸ LicenÃ§a

Este projeto Ã© distribuÃ­do sob a licenÃ§a de **Nozes (o povo estudante hehe)**.  
Sinta-se Ã  vontade para usar, modificar e contribuir. ğŸ’™  

---

> â€œA tecnologia pode ouvir, mas Ã© o humano que acolhe.â€
